{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPQD71AifBBI"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Difficulty tagger/diff_dataset_new.csv' #loading the csv file\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "#handling missing values in textual columns\n",
        "data['Body'] = data['Body'].fillna('')\n",
        "data['Title'] = data['Title'].fillna('')\n",
        "data['Tags'] = data['Tags'].fillna('')\n",
        "\n",
        "numerical_cols = [\n",
        "    'User_Reputation', 'Bronze_badge', 'Gold_badge', 'Silver_badge',\n",
        "    'User Id', 'Accepted Answer ID', 'View Count',\n",
        "    'Answer Count', 'Score', 'Interval from first', 'Interval from accepted',\n",
        "    'Total count urls and imgs', 'LOC', 'Question_Length'\n",
        "]\n",
        "\n",
        "# Impute missing values for numerical features\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data[numerical_cols] = imputer.fit_transform(data[numerical_cols])\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "\n",
        "# Loading different models for generating text embeddings\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "# model = SentenceTransformer(\"BAAI/bge-m3\")\n",
        "# model = SentenceTransformer(\"flax-sentence-embeddings/stackoverflow_mpnet-base\")\n",
        "# model = SentenceTransformer(\"hkunlp/instructor-xl\")\n",
        "\n",
        "# Encoding all the text data and concatenating their embeddings\n",
        "title_embeddings = model.encode(data['Title'].tolist(), show_progress_bar=True)\n",
        "body_embeddings = model.encode(data['Body'].tolist(), show_progress_bar=True)\n",
        "tags_embeddings = model.encode(data['Tags'].tolist(), show_progress_bar=True)\n",
        "\n",
        "# Combining them into a single array\n",
        "text_embeddings = np.hstack((title_embeddings, body_embeddings, tags_embeddings))\n",
        "\n",
        "# Now combining text embeddings with numerical features\n",
        "numerical_features = data[numerical_cols]\n",
        "combined_features = np.hstack((text_embeddings, numerical_features))\n",
        "\n",
        "# label encoding -\n",
        "label_mapping = {'Basic': 0, 'Intermediate': 1, 'Advanced': 2}\n",
        "labels = data['Label'].map(label_mapping).values\n",
        "\n",
        "# data splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "# Applying SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "#Applying Grid search for cross validation and hyperparameter tuning\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "scorer = make_scorer(accuracy_score)\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, scoring=scorer, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Best Score: {best_score}\")\n",
        "\n",
        "#Fitting with best parameters\n",
        "clf = RandomForestClassifier(random_state=42, **best_params)\n",
        "clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Evaluation of model -\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=label_mapping.keys()))\n",
        "\n",
        "# Saving the trained model and other relevant functions for later use in the extension backend\n",
        "with open('trained_classifier_if.pkl', 'wb') as f:\n",
        "    pickle.dump(clf, f)\n",
        "print(\"Trained classifier saved as 'trained_classifier_if.pkl'\")\n",
        "\n",
        "with open('imputer_if.pkl', 'wb') as f:\n",
        "    pickle.dump(imputer, f)\n",
        "print(\"Trained imputer saved as 'imputer_if.pkl'\")\n",
        "\n",
        "with open('scaler_if.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(\"Trained scaler saved as 'scaler_if.pkl'\")\n"
      ]
    }
  ]
}