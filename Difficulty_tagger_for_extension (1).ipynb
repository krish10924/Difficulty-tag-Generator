{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YVKxtkZVu7zD",
        "wV6UfaLMuzic"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#text and numerical combined"
      ],
      "metadata": {
        "id": "YVKxtkZVu7zD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQO_pn7OZI62"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/IIT Work/Difficulty tagger/java_code_embeddings.csv\")\n",
        "\n",
        "data.head()\n",
        "\n",
        "\n",
        "# Text preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove punctuation\n",
        "    tokens = [token.lower() for token in tokens if token not in string.punctuation]\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n",
        "\n",
        "data['Processed Body'] = data['Processed Body'].apply(preprocess_text)\n",
        "data['Title'] = data['Title'].apply(preprocess_text)\n",
        "\n",
        "\n",
        "# Define text and numerical features\n",
        "text_features = ['Title',\t'Processed Body',\t'Tags',\t'Code Final'\t]  # Replace with the names of your text columns\n",
        "numerical_features = ['LOC', 'Question_Length', 'Total count urls and imgs', 'View Count', 'Answer Count', 'Score', 'User_Reputation', 'Bronze_badge', 'Gold_badge', 'Silver_badge', 'Accept_rate', 'Interval from first', 'Interval from accepted']\n",
        "\n",
        "# Preprocessing pipelines for text and numerical data\n",
        "text_pipeline = ColumnTransformer([\n",
        "    ('tfidf', TfidfVectorizer(), 'Title'),\n",
        "    ('tfidf2', TfidfVectorizer(), 'Processed Body'),\n",
        "    ('tfidf3', TfidfVectorizer(), 'Tags'),\n",
        "    ('tfidf4', TfidfVectorizer(), 'Code Final'),\n",
        "], remainder='passthrough')\n",
        "\n",
        "numerical_pipeline = ColumnTransformer([\n",
        "    ('imputer', SimpleImputer(strategy='mean'), numerical_features),\n",
        "    ('scaler', StandardScaler(), numerical_features),\n",
        "])\n",
        "\n",
        "# Combine the processed text and numerical features\n",
        "combined_features = FeatureUnion([\n",
        "    ('text', text_pipeline),\n",
        "    ('numerical', numerical_pipeline),\n",
        "])\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data[text_features + numerical_features]\n",
        "y = data['Label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the data\n",
        "X_train_processed = combined_features.fit_transform(X_train)\n",
        "X_test_processed = combined_features.transform(X_test)\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_processed = imputer.fit_transform(X_train_processed)\n",
        "X_test_processed = imputer.transform(X_test_processed)\n",
        "\n",
        "# Train the classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train_processed, y_train)\n",
        "\n",
        "# Predict the labels for test set\n",
        "y_pred = rf_classifier.predict(X_test_processed)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Function to get user input and make prediction\n",
        "def predict_label():\n",
        "    input_data = {}\n",
        "    for feature in text_features + numerical_features:\n",
        "        input_data[feature] = input(f\"Enter value for '{feature}': \")\n",
        "\n",
        "    # Preprocess the user input\n",
        "    input_df = pd.DataFrame([input_data])\n",
        "    input_processed = combined_features.transform(input_df)\n",
        "    input_processed = imputer.transform(input_processed)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = rf_classifier.predict(input_processed)\n",
        "    print(\"Predicted Label:\", prediction[0])\n",
        "\n",
        "# Make predictions based on user input\n",
        "predict_label()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained model to a file\n",
        "with open('rf_classifier_model.pkl', 'wb') as f:\n",
        "    pickle.dump(rf_classifier, f)\n"
      ],
      "metadata": {
        "id": "YAEZid4rsCB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model from the pickle file\n",
        "with open('rf_classifier_model.pkl', 'rb') as f:\n",
        "    rf_classifier_loaded = pickle.load(f)\n",
        "\n",
        "# Function to get user input and make prediction using the loaded model\n",
        "def predict_label_loaded():\n",
        "    input_data = {}\n",
        "    for feature in text_features + numerical_features:\n",
        "        input_data[feature] = input(f\"Enter value for '{feature}': \")\n",
        "\n",
        "    # Preprocess the user input\n",
        "    input_df = pd.DataFrame([input_data])\n",
        "    input_processed = combined_features.transform(input_df)\n",
        "    input_processed = imputer.transform(input_processed)\n",
        "\n",
        "    # Make prediction using the loaded model\n",
        "    prediction = rf_classifier_loaded.predict(input_processed)\n",
        "    print(\"Predicted Label:\", prediction[0])\n",
        "\n",
        "# Make predictions based on user input using the loaded model\n",
        "predict_label_loaded()\n"
      ],
      "metadata": {
        "id": "0nq3_GaLsD8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Only for text"
      ],
      "metadata": {
        "id": "wV6UfaLMuzic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming 'final_text' is your dataset and 'train_data' is defined\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(final_text, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract features using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train = tfidf_vectorizer.fit_transform(train_data['text_concatenated'])\n",
        "X_test = tfidf_vectorizer.transform(test_data['text_concatenated'])\n",
        "\n",
        "# Convert labels to numerical values\n",
        "label_map = {label: idx for idx, label in enumerate(train_data['Label'].unique())}\n",
        "train_data['Label'] = train_data['Label'].map(label_map)\n",
        "test_data['Label'] = test_data['Label'].map(label_map)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train, train_data['Label'])\n",
        "\n",
        "def predict_label(input_text):\n",
        "    # Preprocess input text\n",
        "    input_features = tfidf_vectorizer.transform([input_text])\n",
        "    # Make prediction\n",
        "    prediction = classifier.predict(input_features)\n",
        "    # Map prediction back to original label\n",
        "    label_map_inverse = {idx: label for label, idx in label_map.items()}\n",
        "    predicted_label = label_map_inverse[prediction[0]]\n",
        "    return predicted_label\n",
        "\n",
        "# Save model and vectorizer to pickle file\n",
        "with open('model.pkl', 'wb') as model_file:\n",
        "    pickle.dump((classifier, tfidf_vectorizer, label_map), model_file)\n",
        "\n",
        "# Example usage:\n",
        "user_input = input(\"Enter some text to predict its label: \")\n",
        "predicted_label = predict_label(user_input)\n",
        "print(\"Predicted label:\", predicted_label)\n"
      ],
      "metadata": {
        "id": "uW37jCaNu1jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the model, vectorizer, and label mapping from the pickle file\n",
        "with open('model.pkl', 'rb') as model_file:\n",
        "    classifier, tfidf_vectorizer, label_map = pickle.load(model_file)\n",
        "\n",
        "def predict_label(input_text):\n",
        "    # Preprocess input text\n",
        "    input_features = tfidf_vectorizer.transform([input_text])\n",
        "    # Make prediction\n",
        "    prediction = classifier.predict(input_features)\n",
        "    # Map prediction back to original label\n",
        "    label_map_inverse = {idx: label for label, idx in label_map.items()}\n",
        "    predicted_label = label_map_inverse[prediction[0]]\n",
        "    return predicted_label\n",
        "\n",
        "# Example usage:\n",
        "user_input = input(\"Enter some text to predict its label: \")\n",
        "predicted_label = predict_label(user_input)\n",
        "print(\"Predicted label:\", predicted_label)\n"
      ],
      "metadata": {
        "id": "5YGEnThKu2Sj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}